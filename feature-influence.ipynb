{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find most important feature in a model predictions using influence functions\n",
    "\n",
    "Pang Wei Koh and Percy Lian show in their [\"Understanding Black-box Predictions via Influence Functions\"](https://arxiv.org/pdf/1703.04730.pdf) (ICML 2017) that influence functions can be used to approximate the learning effect of training data onto the predictions.\n",
    "An extension of this is the ability to approximate the effect of a given perturbation on a training point.\n",
    "\n",
    "The original authors demonstrate how this also enables engineering adversarial training attack. The attack consists in finding the most influential training input for a given test point prediction. Then approximating the perturbation that has the maximally negative learning effect on learning the test point.\n",
    "\n",
    "The author suggest the possibility of using influence functions to approximate the effect of perturbing the training point has a way to analyse the training effects of features.\n",
    "\n",
    "\n",
    "We use the original code from the offical authors repository for the model classes and various utilities. We use the Kaggle [Titanic dataset](https://www.kaggle.com/c/titanic/data) to experiment on the idea of using influence functions to approximate the effect of features on learning in a blackbox model.\n",
    "\n",
    "**Plan**\n",
    "\n",
    "1. Preprocess data\n",
    "2. Train model (logistic regression)\n",
    "3. Test model\n",
    "4. Engineer adversarial training training data to degrade the performance of the model.\n",
    "5. Analyse the noise added to the feature as a characterization of the influence of feature in learning for the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. For each correctly labelled test point:\n",
    "       Find most their influential training points\n",
    "       Approximate the perturbation effect on each point\n",
    "       \n",
    "+ For each feature:\n",
    "\tFor each train point:\n",
    "\t    Get influence on loss of perturbation of given training point on given feature\n",
    "+ Get stats:\n",
    "\t+ Average by feature of their influence on z-test\n",
    "\t+(other stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fpath_titanic = \"/home/eolus/Desktop/Dauphine/datamining/projets/blackBox/data/train.csv\"\n",
    "train_df = pd.read_csv(fpath_titanic)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_prefix(name):\n",
    "    import re\n",
    "    try:\n",
    "        return re.search('(Mr\\.)|(Mrs\\.)|(Miss\\.)', name).group()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "train_df['Prefix'] = train_df.Name.apply(extract_prefix)\n",
    "\n",
    "for cat_col in ['Sex', 'Embarked', 'Prefix' ]:\n",
    "    train_df[cat_col] = pd.factorize(train_df[cat_col])[0]\n",
    "    \n",
    "train_df['Age'].fillna(train_df.Age.mean(), inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Prefix', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "X = np.array(train_df[features])\n",
    "y = np.array((train_df.Survived > 0).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Need to train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataset objects\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "#from influence indataset as dataset\n",
    "from influence.dataset import DataSet\n",
    "import numpy as np\n",
    "lr_train = DataSet(X_train, np.array(y_train, dtype=int))\n",
    "lr_test = DataSet(X_test, np.array(y_test, dtype=int))\n",
    "lr_validation = None\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "lr_data_sets = base.Datasets(train=lr_train, validation=lr_validation, test=lr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eolus/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py:249: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Total number of parameters: 8\n",
      "Using normal model\n",
      "LBFGS training took [10] iter.\n",
      "After training with LBFGS: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eolus/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:97: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "from influence.binaryLogisticRegressionWithLBFGS import BinaryLogisticRegressionWithLBFGS\n",
    "\n",
    "num_classes = 2\n",
    "input_dim = len(features)\n",
    "\n",
    "weight_decay = 0.01\n",
    "batch_size = 100\n",
    "initial_learning_rate = 0.001 \n",
    "keep_probs = None\n",
    "decay_epochs = [1000, 10000]\n",
    "max_lbfgs_iter = 1000\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_model = BinaryLogisticRegressionWithLBFGS(\n",
    "    input_dim=input_dim,\n",
    "    weight_decay=weight_decay,\n",
    "    max_lbfgs_iter=max_lbfgs_iter,\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=lr_data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    keep_probs=keep_probs,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=False,\n",
    "    train_dir='tmp',\n",
    "    log_dir='tmp',\n",
    "    model_name='titanic')\n",
    "\n",
    "tf_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives: 100\n",
      "true_negatives: 137\n",
      "false_positives 38\n",
      "false_negatives 20\n"
     ]
    }
   ],
   "source": [
    "# Retrieve test predictions and reference labels\n",
    "preds_p = tf_model.get_preds().tolist()\n",
    "preds = [1 if el[0] < 0.5 else 0 for el in preds_p]\n",
    "ref = tf_model.data_sets.test.labels\n",
    "\n",
    "# True/False - Positives/Negatives    \n",
    "true_pos = [(i, p) for i, p in enumerate(preds_p) if p[0] < p[1] and ref[i] == 1]\n",
    "true_neg = [(i, p) for i, p in enumerate(preds_p) if p[0] > p[1] and ref[i] == 0]\n",
    "false_pos = [(i, p) for i, p in enumerate(preds_p) if p[0] < p[1] and ref[i] == 0]\n",
    "false_neg = [(i, p) for i, p in enumerate(preds_p) if p[0] > p[1] and ref[i] == 1]\n",
    "\n",
    "# Confusion matrix data\n",
    "print(\"true_positives:\", len(true_pos))\n",
    "print(\"true_negatives:\", len(true_neg))\n",
    "print(\"false_positives\", len(false_pos))\n",
    "print(\"false_negatives\", len(false_neg))\n",
    "\n",
    "# Sort true_positives and true_negatives by how confident the model is\n",
    "true_pos_top = sorted(true_pos, key=lambda x : x[1][0], reverse=False)\n",
    "true_neg_top = sorted(true_neg, key=lambda x : x[1][0], reverse=True)\n",
    "\n",
    "# Sample down (top 10)\n",
    "true_pos_top = true_pos_top[:30]\n",
    "true_neg_top = true_neg_top[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most influential train points\n",
    "\n",
    "For each true positive / true negative prediction for which the model predicted with high confidence, we approximate which train points are most responsible for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_train_influence(idx):\n",
    "    \"\"\"\n",
    "    Approximate most influential train points for a test point\n",
    "    idx : index of test point\n",
    "    \"\"\"\n",
    "    num_train = len(tf_model.data_sets.train.labels)\n",
    "    influences = tf_model.get_influence_on_test_loss(\n",
    "        [idx], \n",
    "        np.arange(len(tf_model.data_sets.train.labels)),\n",
    "        force_refresh=True) * num_train\n",
    "    influences_sorted = sorted(enumerate(influences),\n",
    "                               key=lambda x:x[1],\n",
    "                               reverse=True)\n",
    "    influences_sorted = influences_sorted[:10]\n",
    "    return influences_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.026063\n",
      "         Iterations: 4\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 82\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.030229\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.064258\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 22\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.030219\n",
      "         Iterations: 5\n",
      "         Function evaluations: 134\n",
      "         Gradient evaluations: 126\n",
      "         Hessian evaluations: 26\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.070613\n",
      "         Iterations: 5\n",
      "         Function evaluations: 74\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 28\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.024056\n",
      "         Iterations: 4\n",
      "         Function evaluations: 87\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.098777\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.029434\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 18\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.052283\n",
      "         Iterations: 4\n",
      "         Function evaluations: 80\n",
      "         Gradient evaluations: 72\n",
      "         Hessian evaluations: 16\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.033581\n",
      "         Iterations: 5\n",
      "         Function evaluations: 157\n",
      "         Gradient evaluations: 147\n",
      "         Hessian evaluations: 26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.044321\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 20\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.038101\n",
      "         Iterations: 5\n",
      "         Function evaluations: 109\n",
      "         Gradient evaluations: 100\n",
      "         Hessian evaluations: 25\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.089138\n",
      "         Iterations: 5\n",
      "         Function evaluations: 161\n",
      "         Gradient evaluations: 151\n",
      "         Hessian evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.050444\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.070148\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 18\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.082222\n",
      "         Iterations: 5\n",
      "         Function evaluations: 94\n",
      "         Gradient evaluations: 87\n",
      "         Hessian evaluations: 23\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.066799\n",
      "         Iterations: 5\n",
      "         Function evaluations: 151\n",
      "         Gradient evaluations: 143\n",
      "         Hessian evaluations: 25\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.085513\n",
      "         Iterations: 4\n",
      "         Function evaluations: 69\n",
      "         Gradient evaluations: 61\n",
      "         Hessian evaluations: 16\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.118542\n",
      "         Iterations: 4\n",
      "         Function evaluations: 72\n",
      "         Gradient evaluations: 67\n",
      "         Hessian evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.138585\n",
      "         Iterations: 7\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.075918\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.160956\n",
      "         Iterations: 7\n",
      "         Function evaluations: 23\n",
      "         Gradient evaluations: 29\n",
      "         Hessian evaluations: 21\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.101718\n",
      "         Iterations: 5\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.140622\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 14\n",
      "         Hessian evaluations: 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.106632\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 20\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.139495\n",
      "         Iterations: 7\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 15\n",
      "         Hessian evaluations: 24\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.167387\n",
      "         Iterations: 4\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 75\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.160456\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 21\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.163622\n",
      "         Iterations: 7\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.172707\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 16\n",
      "         Hessian evaluations: 21\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.219252\n",
      "         Iterations: 7\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 15\n",
      "         Hessian evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.474698\n",
      "         Iterations: 6\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 12\n",
      "         Hessian evaluations: 22\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.190590\n",
      "         Iterations: 7\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 25\n",
      "         Hessian evaluations: 23\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.358243\n",
      "         Iterations: 5\n",
      "         Function evaluations: 69\n",
      "         Gradient evaluations: 62\n",
      "         Hessian evaluations: 23\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.291692\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 14\n",
      "         Hessian evaluations: 21\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.162535\n",
      "         Iterations: 5\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 74\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.166461\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 14\n",
      "         Hessian evaluations: 19\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.265753\n",
      "         Iterations: 5\n",
      "         Function evaluations: 148\n",
      "         Gradient evaluations: 139\n",
      "         Hessian evaluations: 26\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.311592\n",
      "         Iterations: 5\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 71\n",
      "         Hessian evaluations: 23\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.823891\n",
      "         Iterations: 5\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 70\n",
      "         Hessian evaluations: 23\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.292590\n",
      "         Iterations: 4\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 73\n",
      "         Hessian evaluations: 21\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.160750\n",
      "         Iterations: 4\n",
      "         Function evaluations: 67\n",
      "         Gradient evaluations: 59\n",
      "         Hessian evaluations: 15\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.174875\n",
      "         Iterations: 4\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 17\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.181336\n",
      "         Iterations: 6\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 22\n",
      "         Hessian evaluations: 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.250524\n",
      "         Iterations: 7\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 24\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.244096\n",
      "         Iterations: 6\n",
      "         Function evaluations: 71\n",
      "         Gradient evaluations: 65\n",
      "         Hessian evaluations: 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.236786\n",
      "         Iterations: 7\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 24\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.267839\n",
      "         Iterations: 5\n",
      "         Function evaluations: 95\n",
      "         Gradient evaluations: 88\n",
      "         Hessian evaluations: 19\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -1.334540\n",
      "         Iterations: 7\n",
      "         Function evaluations: 208\n",
      "         Gradient evaluations: 200\n",
      "         Hessian evaluations: 32\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.215643\n",
      "         Iterations: 5\n",
      "         Function evaluations: 75\n",
      "         Gradient evaluations: 69\n",
      "         Hessian evaluations: 18\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.282789\n",
      "         Iterations: 6\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 20\n",
      "         Hessian evaluations: 20\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.207017\n",
      "         Iterations: 5\n",
      "         Function evaluations: 72\n",
      "         Gradient evaluations: 66\n",
      "         Hessian evaluations: 18\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.207153\n",
      "         Iterations: 5\n",
      "         Function evaluations: 85\n",
      "         Gradient evaluations: 79\n",
      "         Hessian evaluations: 18\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.208000\n",
      "         Iterations: 5\n",
      "         Function evaluations: 83\n",
      "         Gradient evaluations: 76\n",
      "         Hessian evaluations: 22\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.511420\n",
      "         Iterations: 6\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 135\n",
      "         Hessian evaluations: 25\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.318662\n",
      "         Iterations: 5\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 78\n",
      "         Hessian evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.211774\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 16\n",
      "         Hessian evaluations: 21\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.212073\n",
      "         Iterations: 6\n",
      "         Function evaluations: 84\n",
      "         Gradient evaluations: 78\n",
      "         Hessian evaluations: 20\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.212981\n",
      "         Iterations: 8\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 39\n",
      "         Hessian evaluations: 27\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -0.213345\n",
      "         Iterations: 6\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 146\n",
      "         Hessian evaluations: 21\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get test points indices\n",
    "true_pos_top_idx = [top_pos[0] for top_pos in true_pos_top]\n",
    "true_neg_top_idx = [top_neg[0] for top_neg in true_neg_top]\n",
    "\n",
    "# Approximate most influential train points for each test point\n",
    "influence_train_true_pos = [get_top_train_influence(idx) for idx in true_pos_top_idx]\n",
    "influence_train_true_neg = [get_top_train_influence(idx) for idx in true_neg_top_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most important features for each prediction using the influence perturbation function\n",
    "\n",
    "For each influential train point, we get the gradient of influence wrt to input to estimate the perturbation that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_pert_influence(train_indices, test_idx):\n",
    "    \"\"\"\n",
    "    Approximate most grad of influence wrt training points in order to\n",
    "    find most important feature.\n",
    "    \"\"\"\n",
    "    influences_grad = tf_model.get_grad_of_influence_wrt_input(\n",
    "        train_indices, [test_idx], force_refresh=False)\n",
    "    return influences_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_pos_influences_grad = [] \n",
    "for test_idx, train_top in zip(true_pos_top_idx, influence_train_true_pos):\n",
    "    train_indices = [r[0] for r in train_top]\n",
    "    top_pert_influence = get_top_pert_influence(train_indices, test_idx)\n",
    "    true_pos_influences_grad.append(top_pert_influence)\n",
    "\n",
    "true_neg_influences_grad = [] \n",
    "for test_idx, train_top in zip(true_neg_top_idx, influence_train_true_neg):\n",
    "    train_indices = [r[0] for r in train_top]\n",
    "    top_pert_influence = get_top_pert_influence(train_indices, test_idx)\n",
    "    true_neg_influences_grad.append(top_pert_influence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze: mean var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_pos_influences_grad[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Benchmark feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8203389830508474"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, step=3, cv=3)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "selector.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38991178, -0.71842588,  1.00059846, -0.29151786, -0.37872978,\n",
       "       -0.0958028 ,  0.1934243 ,  0.16377468])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.estimator_.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Coeffs\n",
      "============================\n",
      "('Sex', 1.0005984599032838)\n",
      "('Pclass', -0.7184258754192752)\n",
      "('Prefix', 0.3899117807908663)\n",
      "('SibSp', -0.3787297807952296)\n",
      "('Age', -0.2915178644724024)\n",
      "('Fare', 0.19342430434726862)\n",
      "('Embarked', 0.16377467883922647)\n",
      "('Parch', -0.09580280432420257)\n",
      "\n",
      "Influence function\n",
      "============================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sorted_logit_influence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fb4bfcbb22a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nInfluence function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"============================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_logit_influence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_logit_influence' is not defined"
     ]
    }
   ],
   "source": [
    "features_importance = zip(features, selector.estimator_.coef_[0])\n",
    "sorted_logit_coefs = sorted(features_importance, key=lambda x : abs(x[1]), reverse=True)\n",
    "print(\"\\nLogistic Regression Coeffs\")\n",
    "print(\"============================\")\n",
    "for el in sorted_logit_coefs:\n",
    "    print(el)\n",
    "\n",
    "    \n",
    "print(\"\\nInfluence function\")\n",
    "print(\"============================\")\n",
    "for el in sorted_logit_influence:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Average influence on all test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_influence_pert(test_idx, tf_model):\n",
    "    \n",
    "    num_train = len(tf_model.data_sets.train.labels)\n",
    "    \n",
    "    influences_grad = tf_model.get_grad_of_influence_wrt_input(\n",
    "        np.arange(num_train),\n",
    "        test_idx, \n",
    "        force_refresh=False)\n",
    "\n",
    "    influence_grad_top_features = influences_grad[top_influence_ix, :]\n",
    "\n",
    "    avg_inf_pert = [np.mean(col) for col in influence_grad_top_features.T]\n",
    "    features_avg_inf = zip(features, avg_inf_pert)\n",
    "\n",
    "    sorted_logit_influence = sorted(features_avg_inf, key=lambda x : abs(x[1]), reverse=True)\n",
    "    \n",
    "    print()\n",
    "    for el in sorted_logit_influence:\n",
    "        print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_idx = list(range(50))\n",
    "get_feature_influence_pert(test_idx, tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure influence on multiple test points of a similar label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find indices of sampleztest with Survived == 1\n",
    "#[y_test == 1]\n",
    "\n",
    "\n",
    "sample_ix_pos_y = np.where(y_test == 1)[0].tolist()[:50]\n",
    "sample_ix_neg_y = np.where(y_test == 0)[0].tolist()[:50]\n",
    "\n",
    "\n",
    "print(\"Class : Survived\")\n",
    "print(\"===================\")\n",
    "get_feature_influence_pert(sample_ix_pos_y, tf_model)\n",
    "\n",
    "print(\"\\n\\nClass : Died miserably\")\n",
    "print(\"===================\")\n",
    "get_feature_influence_pert(sample_ix_neg_y, tf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Faire analyse de prior\n",
    "\n",
    "#+ Fare value given Dead / Alive\n",
    "#+ PClass value given dead / alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import pylab\n",
    "\n",
    "x = X_test[:, features.index('Fare')]\n",
    "y = y_test\n",
    "\n",
    "matplotlib.pyplot.scatter(y, x)\n",
    "\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(np.where(X_test[:, features.index('Fare')] <0 )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import pylab\n",
    "\n",
    "x = X_test[:, features.index('Pclass')]\n",
    "y = y_test\n",
    "\n",
    "matplotlib.pyplot.scatter(y, x)\n",
    "\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
